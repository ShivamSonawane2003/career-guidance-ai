"""
Agent Module: Orchestrates conversation flow using LangChain.
Enforces one-question-at-a-time rule and manages conversation state.
"""

import json
import os
import logging
from typing import Dict, Optional, List, Tuple
from career_agent.logic import StreamDetector, CareerRecommender, StudentProfile
from career_agent.llm import LLMProvider

logger = logging.getLogger(__name__)


class CareerGuidanceAgent:
    """Main agent orchestrating the career guidance conversation."""
    
    # Conversation phases
    PHASE_WELCOME = "welcome"
    PHASE_GENERAL_QUESTIONS = "general_questions"
    PHASE_STREAM_CONFIRMATION = "stream_confirmation"
    PHASE_STREAM_QUESTIONS = "stream_questions"
    PHASE_RECOMMENDATIONS = "recommendations"
    PHASE_COMPLETE = "complete"
    
    def __init__(self):
        self.profile = StudentProfile()
        self.stream_detector = StreamDetector()
        self.recommender = CareerRecommender()
        self.llm = LLMProvider()
        self.phase = self.PHASE_WELCOME
        self.current_question_index = 0
        self.stream_question_index = 0
        self.language = "en"
        self.language_manually_set = False  # Track if language was manually set
        
        # Load questions - handle path correctly
        data_file = os.path.join(os.path.dirname(__file__), "data.json")
        with open(data_file, "r", encoding="utf-8") as f:
            self.data = json.load(f)
        
        # Calculate total questions dynamically
        general_count = len(self.data["questions"]["general"])
        # Get max stream questions (assuming all streams have same count)
        max_stream_questions = 0
        for stream_questions in self.data["questions"]["stream_specific"].values():
            max_stream_questions = max(max_stream_questions, len(stream_questions))
        self.total_questions = general_count + max_stream_questions
        logger.info(f"Total questions calculated: {general_count} general + {max_stream_questions} stream-specific = {self.total_questions}")
    
    def _get_question_text(self, question: Dict, question_number: int = None, total_questions: int = None) -> str:
        """Get question text in current language, personalized with name if available."""
        if not question:
            logger.error("Question is None or empty")
            return self._get_welcome_message()
        
        key = "text_mr" if self.language == "mr" else "text_en"
        text = question.get(key, "")
        
        # Fallback to English if Marathi not found
        if not text and self.language == "mr":
            logger.warning(f"Marathi text not found for question {question.get('id', 'unknown')}, falling back to English")
            text = question.get("text_en", "")
        
        # Final fallback
        if not text:
            logger.error(f"No text found for question {question.get('id', 'unknown')} in language {self.language}")
            text = "Question not available" if self.language == "en" else "‡§™‡•ç‡§∞‡§∂‡•ç‡§® ‡§â‡§™‡§≤‡§¨‡•ç‡§ß ‡§®‡§æ‡§π‡•Ä"
        
        # Personalize with name if available (except for name question itself)
        name = self.profile.get("name", "").strip()
        if name and question.get("id") != "name":
            if self.language == "mr":
                text = f"{name}, {text}"
            else:
                text = f"{name}, {text}"
        
        # Add question number prefix if provided (format: "1 of 9 question:")
        if question_number is not None and total_questions is not None:
            if self.language == "mr":
                prefix = f"{question_number} ‡§™‡•à‡§ï‡•Ä {total_questions} ‡§™‡•ç‡§∞‡§∂‡•ç‡§®: "
            else:
                prefix = f"{question_number} of {total_questions} question: "
            text = prefix + text
        
        logger.debug(f"Getting question text in language '{self.language}', key '{key}', question_id: {question.get('id', 'unknown')}, text_length: {len(text)}")
        return text
    
    def _detect_language(self, text: str):
        """Detect and set language from first user input."""
        if self.language == "en":  # Only detect on first input
            logger.debug(f"Detecting language from text: {text[:50]}...")
            detected = self.stream_detector.detect_language(text)
            self.language = detected
            self.profile.set_language(detected)
            logger.info(f"Language detected and set: {self.language}")
    
    def set_language(self, language: str):
        """Manually set language preference."""
        if language in ["en", "mr"]:
            self.language = language
            self.profile.set_language(language)
            self.language_manually_set = True  # Mark as manually set
            logger.info(f"Language manually set to: {self.language}")
        else:
            logger.warning(f"Invalid language code: {language}, keeping current language: {self.language}")
    
    def _get_welcome_message(self) -> str:
        """Get welcome message in current language."""
        if self.language == "mr":
            return "‡§®‡§Æ‡§∏‡•ç‡§ï‡§æ‡§∞! üëã ‡§Æ‡•Ä ‡§§‡•Å‡§Æ‡§ö‡§æ ‡§ï‡§∞‡§ø‡§Ö‡§∞ ‡§Æ‡§æ‡§∞‡•ç‡§ó‡§¶‡§∞‡•ç‡§∂‡§® ‡§∏‡§π‡§æ‡§Ø‡•ç‡§Ø‡§ï ‡§Ü‡§π‡•á. ‡§Æ‡•Ä ‡§§‡•Å‡§Æ‡•ç‡§π‡§æ‡§≤‡§æ ‡§§‡•Å‡§Æ‡§ö‡•ç‡§Ø‡§æ ‡§Ü‡§µ‡§°‡•Ä ‡§Ü‡§£‡§ø ‡§∂‡§ï‡•ç‡§§‡•Ä‡§Ç‡§∂‡•Ä ‡§ú‡•Å‡§≥‡§£‡§æ‡§∞‡•á ‡§ï‡§∞‡§ø‡§Ö‡§∞ ‡§Æ‡§æ‡§∞‡•ç‡§ó ‡§∂‡•ã‡§ß‡§£‡•ç‡§Ø‡§æ‡§§ ‡§Æ‡§¶‡§§ ‡§ï‡§∞‡•Ç. ‡§§‡•Å‡§Æ‡•ç‡§π‡§æ‡§≤‡§æ ‡§ö‡§æ‡§Ç‡§ó‡§≤‡•ç‡§Ø‡§æ ‡§™‡•ç‡§∞‡§ï‡§æ‡§∞‡•á ‡§ì‡§≥‡§ñ‡§£‡•ç‡§Ø‡§æ‡§∏‡§æ‡§†‡•Ä ‡§Æ‡•Ä ‡§§‡•Å‡§Æ‡•ç‡§π‡§æ‡§≤‡§æ ‡§ï‡§æ‡§π‡•Ä ‡§™‡•ç‡§∞‡§∂‡•ç‡§® ‡§µ‡§ø‡§ö‡§æ‡§∞‡•Ç, ‡§Ü‡§£‡§ø ‡§®‡§Ç‡§§‡§∞ ‡§§‡•Å‡§Æ‡§ö‡•ç‡§Ø‡§æ‡§∏‡§æ‡§†‡•Ä ‡§Ø‡•ã‡§ó‡•ç‡§Ø ‡§Ö‡§∏‡§≤‡•á‡§≤‡•ç‡§Ø‡§æ ‡§ï‡§∞‡§ø‡§Ö‡§∞ ‡§™‡§∞‡•ç‡§Ø‡§æ‡§Ø‡§æ‡§Ç‡§ö‡•Ä ‡§∂‡§ø‡§´‡§æ‡§∞‡§∏ ‡§ï‡§∞‡•Ç. ‡§∏‡•Å‡§∞‡•Ç ‡§ï‡§∞‡§£‡•ç‡§Ø‡§æ‡§∏‡§æ‡§†‡•Ä ‡§§‡§Ø‡§æ‡§∞ ‡§Ü‡§π‡§æ‡§§?"
        else:
            return "Hi there! üëã I'm here to help you explore career paths that match your interests and strengths. I'll ask you a few questions to get to know you better, and then suggest some career options that might be perfect for you. Ready to get started?"
    
    def _get_next_general_question(self) -> Optional[Dict]:
        """Get next general question."""
        questions = self.data["questions"]["general"]
        if self.current_question_index < len(questions):
            return questions[self.current_question_index]
        return None
    
    def _get_stream_questions(self, stream: str) -> List[Dict]:
        """Get stream-specific questions."""
        return self.data["questions"]["stream_specific"].get(stream, [])
    
    def _generate_stream_confirmation_prompt(self, detected_stream: str) -> str:
        """Generate prompt to confirm detected stream in a natural way."""
        stream_name = self.data["streams"][detected_stream]["name"]
        name = self.profile.get("name", "").strip()
        name_prefix = f"{name}, " if name else ""
        
        if self.language == "mr":
            return f"{name_prefix}‡§§‡•Å‡§Æ‡•ç‡§π‡•Ä ‡§Æ‡§≤‡§æ ‡§ú‡•á ‡§∏‡§æ‡§Ç‡§ó‡§ø‡§§‡§≤‡•á ‡§Ü‡§π‡•á ‡§§‡•ç‡§Ø‡§æ‡§µ‡§∞‡•Ç‡§®, ‡§Æ‡§≤‡§æ ‡§Ö‡§∏‡•á ‡§µ‡§æ‡§ü‡§§‡•á ‡§ï‡•Ä ‡§§‡•Å‡§Æ‡•ç‡§π‡•Ä {stream_name} ‡§∏‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Æ‡§Æ‡§ß‡•ç‡§Ø‡•á ‡§Ö‡§∏‡§æ‡§≤. ‡§π‡•á ‡§¨‡§∞‡•ã‡§¨‡§∞ ‡§Ü‡§π‡•á ‡§ï‡§æ? (‡§π‡•ã‡§Ø/‡§®‡§æ‡§π‡•Ä)"
        else:
            return f"{name_prefix}Based on everything you've shared with me, it seems like you might be in the {stream_name} stream. Does that sound right to you? (Yes/No)"
    
    def _generate_recommendations(self) -> List[Dict]:
        """Generate career recommendations using rule-based filtering and Gemini LLM enhancement."""
        stream = self.profile.get("stream")
        logger.info(f"Generating recommendations for stream: {stream}")
        if not stream:
            logger.warning("No stream set in profile, cannot generate recommendations")
            return []
        
        # Rule-based filtering (CRITICAL: ensures stream alignment)
        logger.debug(f"Filtering careers for stream {stream} with profile: {list(self.profile.to_dict().keys())}")
        filtered_careers = self.recommender.filter_careers(stream, self.profile.to_dict())
        logger.info(f"Filtered {len(filtered_careers)} careers for stream {stream}")
        
        if not filtered_careers:
            logger.warning("No careers found after filtering")
            return []
        
        # Use Gemini to enhance recommendations with personalized explanations
        if not self.llm.use_gemini:
            logger.warning("Gemini not available, using rule-based formatting only")
            # Fallback to rule-based if Gemini not available
            recommendations = []
            for career in filtered_careers[:3]:
                if not StreamDetector.validate_stream_alignment(career["name"], stream, self.data):
                    logger.warning(f"Skipping invalid career: {career['name']} for stream: {stream}")
                    continue
                formatted = self.recommender.format_recommendation(career, stream, self.language)
                recommendations.append(formatted)
            logger.info(f"Generated {len(recommendations)} recommendations using rule-based formatting (Gemini unavailable)")
            return recommendations[:3]
        
        logger.info("Using Gemini to generate personalized recommendations")
        try:
            recommendations = self._generate_recommendations_with_gemini(filtered_careers, stream)
            logger.info(f"Gemini successfully generated {len(recommendations)} recommendations")
            return recommendations[:3]
        except Exception as e:
            logger.error(f"Gemini recommendation generation failed: {e}, falling back to rule-based formatting", exc_info=True)
            # Fallback to rule-based formatting if Gemini fails
            recommendations = []
            for career in filtered_careers[:3]:
                if not StreamDetector.validate_stream_alignment(career["name"], stream, self.data):
                    logger.warning(f"Skipping invalid career: {career['name']} for stream: {stream}")
                    continue
                formatted = self.recommender.format_recommendation(career, stream, self.language)
                recommendations.append(formatted)
            logger.info(f"Fallback: Generated {len(recommendations)} recommendations using rule-based formatting")
            return recommendations[:3]
    
    def _generate_recommendations_with_gemini(self, filtered_careers: List[Dict], stream: str) -> List[Dict]:
        """Use Gemini to generate personalized career recommendations."""
        # Build student profile summary for Gemini
        profile_summary = self._build_profile_summary()
        
        # Build career data for Gemini - send all available careers to give Gemini more options
        careers_info = []
        for career in filtered_careers:
            careers_info.append({
                "name": career["name"],
                "pathway": career["pathway"],
                "entrance_exams": career["entrance_exams"],
                "skills": career["skills"],
                "risks": career["risks"]
            })
        
        # Create prompt for Gemini with explicit instruction for exactly 3 recommendations
        if self.language == "mr":
            system_prompt = """‡§§‡•Å‡§Æ‡•ç‡§π‡•Ä ‡§è‡§ï ‡§ï‡§∞‡§ø‡§Ö‡§∞ ‡§Æ‡§æ‡§∞‡•ç‡§ó‡§¶‡§∞‡•ç‡§∂‡§® ‡§∏‡§π‡§æ‡§Ø‡•ç‡§Ø‡§ï ‡§Ü‡§π‡§æ‡§§. ‡§§‡•Å‡§Æ‡•ç‡§π‡§æ‡§≤‡§æ ‡§µ‡§ø‡§¶‡•ç‡§Ø‡§æ‡§∞‡•ç‡§•‡•ç‡§Ø‡§æ‡§ö‡•ç‡§Ø‡§æ ‡§™‡•ç‡§∞‡•ã‡§´‡§æ‡§á‡§≤‡§µ‡§∞ ‡§Ü‡§ß‡§æ‡§∞‡§ø‡§§ ‡§®‡§ï‡•ç‡§ï‡•Ä 3 ‡§ï‡§∞‡§ø‡§Ö‡§∞ ‡§∂‡§ø‡§´‡§æ‡§∞‡§∏‡•Ä ‡§¶‡•ç‡§Ø‡§æ‡§µ‡•ç‡§Ø‡§æ ‡§≤‡§æ‡§ó‡§§‡•Ä‡§≤. 
‡§™‡•ç‡§∞‡§§‡•ç‡§Ø‡•á‡§ï ‡§∂‡§ø‡§´‡§æ‡§∞‡§∏‡•Ä‡§∏‡§æ‡§†‡•Ä, ‡§ñ‡§æ‡§≤‡•Ä‡§≤ ‡§Æ‡§æ‡§π‡§ø‡§§‡•Ä ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡§æ:
1. ‡§ï‡§∞‡§ø‡§Ö‡§∞ ‡§®‡§æ‡§µ
2. ‡§∏‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Æ ‡§î‡§ö‡§ø‡§§‡•ç‡§Ø (‡§ï‡§æ ‡§π‡•Ä ‡§ï‡§∞‡§ø‡§Ö‡§∞ ‡§Ø‡§æ ‡§∏‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Æ‡§∂‡•Ä ‡§∏‡§Ç‡§∞‡•á‡§ñ‡§ø‡§§ ‡§Ü‡§π‡•á)
3. ‡§∂‡•à‡§ï‡•ç‡§∑‡§£‡§ø‡§ï ‡§Æ‡§æ‡§∞‡•ç‡§ó
4. ‡§™‡•ç‡§∞‡§µ‡•á‡§∂ ‡§™‡§∞‡•Ä‡§ï‡•ç‡§∑‡§æ
5. ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï ‡§ï‡•å‡§∂‡§≤‡•ç‡§Ø‡•á
6. ‡§ú‡•ã‡§ñ‡•Ä‡§Æ/‡§Æ‡§∞‡•ç‡§Ø‡§æ‡§¶‡§æ

‡§Æ‡§π‡§§‡•ç‡§µ‡§æ‡§ö‡•á: 
- ‡§®‡§ï‡•ç‡§ï‡•Ä 3 ‡§ï‡§∞‡§ø‡§Ö‡§∞ ‡§∂‡§ø‡§´‡§æ‡§∞‡§∏‡•Ä ‡§¶‡•ç‡§Ø‡§æ (‡§ï‡§Æ‡•Ä ‡§ï‡§ø‡§Ç‡§µ‡§æ ‡§ú‡§æ‡§∏‡•ç‡§§ ‡§®‡§æ‡§π‡•Ä)
- ‡§ï‡•á‡§µ‡§≥ ‡§¶‡§ø‡§≤‡•á‡§≤‡•ç‡§Ø‡§æ ‡§ï‡§∞‡§ø‡§Ö‡§∞‡§™‡•à‡§ï‡•Ä ‡§®‡§ø‡§µ‡§° ‡§ï‡§∞‡§æ ‡§Ü‡§£‡§ø ‡§§‡•ç‡§Ø‡§æ‡§Ç‡§ö‡•Ä ‡§Æ‡§æ‡§π‡§ø‡§§‡•Ä ‡§µ‡§æ‡§™‡§∞‡§æ
- JSON ‡§∏‡•ç‡§µ‡§∞‡•Ç‡§™‡§æ‡§§ ‡§®‡§ï‡•ç‡§ï‡•Ä 3 ‡§ë‡§¨‡•ç‡§ú‡•á‡§ï‡•ç‡§ü‡•ç‡§∏ ‡§Ö‡§∏‡§≤‡•á‡§≤‡•Ä array ‡§¶‡•ç‡§Ø‡§æ"""
            
            prompt = f"""‡§µ‡§ø‡§¶‡•ç‡§Ø‡§æ‡§∞‡•ç‡§•‡•Ä ‡§™‡•ç‡§∞‡•ã‡§´‡§æ‡§á‡§≤:
{profile_summary}

‡§â‡§™‡§≤‡§¨‡•ç‡§ß ‡§ï‡§∞‡§ø‡§Ö‡§∞ ‡§™‡§∞‡•ç‡§Ø‡§æ‡§Ø ({stream} ‡§∏‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Æ):
{json.dumps(careers_info, ensure_ascii=False, indent=2)}

‡§ï‡•É‡§™‡§Ø‡§æ ‡§Ø‡§æ ‡§™‡•ç‡§∞‡•ã‡§´‡§æ‡§á‡§≤‡§µ‡§∞ ‡§Ü‡§ß‡§æ‡§∞‡§ø‡§§ ‡§®‡§ï‡•ç‡§ï‡•Ä 3 ‡§∏‡§∞‡•ç‡§µ‡•ã‡§§‡•ç‡§§‡§Æ ‡§ï‡§∞‡§ø‡§Ö‡§∞ ‡§∂‡§ø‡§´‡§æ‡§∞‡§∏‡•Ä ‡§¶‡•ç‡§Ø‡§æ. ‡§§‡•Å‡§Æ‡•ç‡§π‡•Ä ‡§®‡§ï‡•ç‡§ï‡•Ä 3 ‡§ï‡§∞‡§ø‡§Ö‡§∞ ‡§®‡§ø‡§µ‡§°‡§≤‡•á ‡§™‡§æ‡§π‡§ø‡§ú‡•á‡§§.

‡§™‡•ç‡§∞‡§§‡•ç‡§Ø‡•á‡§ï ‡§∂‡§ø‡§´‡§æ‡§∞‡§∏‡•Ä‡§∏‡§æ‡§†‡•Ä, JSON ‡§∏‡•ç‡§µ‡§∞‡•Ç‡§™‡§æ‡§§ ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•ç‡§Ø‡§æ (‡§®‡§ï‡•ç‡§ï‡•Ä 3 ‡§ë‡§¨‡•ç‡§ú‡•á‡§ï‡•ç‡§ü‡•ç‡§∏):
[
  {{
    "name": "‡§ï‡§∞‡§ø‡§Ö‡§∞ ‡§®‡§æ‡§µ",
    "stream_justification": "‡§∏‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Æ ‡§î‡§ö‡§ø‡§§‡•ç‡§Ø",
    "pathway": "‡§∂‡•à‡§ï‡•ç‡§∑‡§£‡§ø‡§ï ‡§Æ‡§æ‡§∞‡•ç‡§ó",
    "entrance_exams": ["‡§™‡§∞‡•Ä‡§ï‡•ç‡§∑‡§æ1", "‡§™‡§∞‡•Ä‡§ï‡•ç‡§∑‡§æ2"],
    "skills": ["‡§ï‡•å‡§∂‡§≤‡•ç‡§Ø1", "‡§ï‡•å‡§∂‡§≤‡•ç‡§Ø2"],
    "risks": "‡§ú‡•ã‡§ñ‡•Ä‡§Æ/‡§Æ‡§∞‡•ç‡§Ø‡§æ‡§¶‡§æ"
  }},
  {{
    "name": "‡§ï‡§∞‡§ø‡§Ö‡§∞ ‡§®‡§æ‡§µ 2",
    "stream_justification": "‡§∏‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Æ ‡§î‡§ö‡§ø‡§§‡•ç‡§Ø",
    "pathway": "‡§∂‡•à‡§ï‡•ç‡§∑‡§£‡§ø‡§ï ‡§Æ‡§æ‡§∞‡•ç‡§ó",
    "entrance_exams": ["‡§™‡§∞‡•Ä‡§ï‡•ç‡§∑‡§æ1", "‡§™‡§∞‡•Ä‡§ï‡•ç‡§∑‡§æ2"],
    "skills": ["‡§ï‡•å‡§∂‡§≤‡•ç‡§Ø1", "‡§ï‡•å‡§∂‡§≤‡•ç‡§Ø2"],
    "risks": "‡§ú‡•ã‡§ñ‡•Ä‡§Æ/‡§Æ‡§∞‡•ç‡§Ø‡§æ‡§¶‡§æ"
  }},
  {{
    "name": "‡§ï‡§∞‡§ø‡§Ö‡§∞ ‡§®‡§æ‡§µ 3",
    "stream_justification": "‡§∏‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Æ ‡§î‡§ö‡§ø‡§§‡•ç‡§Ø",
    "pathway": "‡§∂‡•à‡§ï‡•ç‡§∑‡§£‡§ø‡§ï ‡§Æ‡§æ‡§∞‡•ç‡§ó",
    "entrance_exams": ["‡§™‡§∞‡•Ä‡§ï‡•ç‡§∑‡§æ1", "‡§™‡§∞‡•Ä‡§ï‡•ç‡§∑‡§æ2"],
    "skills": ["‡§ï‡•å‡§∂‡§≤‡•ç‡§Ø1", "‡§ï‡•å‡§∂‡§≤‡•ç‡§Ø2"],
    "risks": "‡§ú‡•ã‡§ñ‡•Ä‡§Æ/‡§Æ‡§∞‡•ç‡§Ø‡§æ‡§¶‡§æ"
  }}
]

‡§ï‡•á‡§µ‡§≥ JSON ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•ç‡§Ø‡§æ, ‡§ï‡•ã‡§£‡§§‡•Ä‡§π‡•Ä ‡§Ö‡§§‡§ø‡§∞‡§ø‡§ï‡•ç‡§§ ‡§Æ‡§ú‡§ï‡•Ç‡§∞ ‡§®‡§æ‡§π‡•Ä. ‡§®‡§ï‡•ç‡§ï‡•Ä 3 ‡§ï‡§∞‡§ø‡§Ö‡§∞ ‡§∂‡§ø‡§´‡§æ‡§∞‡§∏‡•Ä ‡§Ö‡§∏‡§£‡•á ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï ‡§Ü‡§π‡•á."""
        else:
            system_prompt = """You are a career guidance assistant. You need to provide exactly 3 career recommendations based on the student's profile.
For each recommendation, provide:
1. Career name
2. Stream justification (why this career aligns with the stream)
3. Education pathway
4. Entrance exams
5. Required skills
6. Risks/limitations

Important: 
- Provide exactly 3 career recommendations (not less, not more)
- Only select from the provided careers and use their information
- Return a JSON array with exactly 3 objects"""
            
            prompt = f"""Student Profile:
{profile_summary}

Available Career Options ({stream} stream):
{json.dumps(careers_info, indent=2)}

Please provide exactly 3 best career recommendations based on this profile. You must select exactly 3 careers.

For each recommendation, respond in JSON format (exactly 3 objects):
[
  {{
    "name": "Career Name 1",
    "stream_justification": "Stream justification",
    "pathway": "Education pathway",
    "entrance_exams": ["Exam1", "Exam2"],
    "skills": ["Skill1", "Skill2"],
    "risks": "Risks/limitations"
  }},
  {{
    "name": "Career Name 2",
    "stream_justification": "Stream justification",
    "pathway": "Education pathway",
    "entrance_exams": ["Exam1", "Exam2"],
    "skills": ["Skill1", "Skill2"],
    "risks": "Risks/limitations"
  }},
  {{
    "name": "Career Name 3",
    "stream_justification": "Stream justification",
    "pathway": "Education pathway",
    "entrance_exams": ["Exam1", "Exam2"],
    "skills": ["Skill1", "Skill2"],
    "risks": "Risks/limitations"
  }}
]

Return ONLY JSON, no additional text. You must provide exactly 3 career recommendations."""
        
        logger.debug(f"Calling Gemini with prompt length: {len(prompt)}")
        logger.info(f"Requesting exactly 3 recommendations from Gemini for stream: {stream}")
        response_text = self.llm.generate(prompt, system_prompt)
        logger.debug(f"Gemini response received, length: {len(response_text)}")
        
        # Parse Gemini response
        recommendations = self._parse_gemini_recommendations(response_text, stream)
        logger.info(f"Gemini returned {len(recommendations)} recommendations")
        
        # Validate and ensure stream alignment
        validated_recommendations = []
        for rec in recommendations:
            # Find original career data
            original_career = None
            for career in filtered_careers:
                if career["name"].lower() == rec["name"].lower():
                    original_career = career
                    break
            
            if original_career:
                # Validate stream alignment
                if StreamDetector.validate_stream_alignment(rec["name"], stream, self.data):
                    # Use Gemini's personalized content but ensure we have all required fields
                    final_rec = {
                        "name": rec["name"],
                        "stream_justification": rec.get("stream_justification", 
                            f"This career aligns with {self.data['streams'][stream]['name']} stream."),
                        "pathway": rec.get("pathway", original_career["pathway"]),
                        "entrance_exams": rec.get("entrance_exams", original_career["entrance_exams"]),
                        "skills": rec.get("skills", original_career["skills"]),
                        "risks": rec.get("risks", original_career["risks"])
                    }
                    validated_recommendations.append(final_rec)
                    logger.info(f"Validated Gemini recommendation: {rec['name']}")
                else:
                    logger.warning(f"Gemini recommendation '{rec['name']}' failed stream validation")
            else:
                logger.warning(f"Gemini recommendation '{rec['name']}' not found in filtered careers")
        
        # Ensure we have exactly 3 recommendations
        if len(validated_recommendations) == 3:
            logger.info("Successfully received exactly 3 recommendations from Gemini")
            return validated_recommendations
        elif len(validated_recommendations) > 3:
            logger.warning(f"Gemini returned {len(validated_recommendations)} recommendations, taking first 3")
            return validated_recommendations[:3]
        else:
            # If Gemini didn't return 3 valid recommendations, fill with rule-based ones
            logger.info(f"Gemini returned {len(validated_recommendations)} valid recommendations, filling remaining with rule-based")
            used_names = [r["name"] for r in validated_recommendations]
            for career in filtered_careers:
                if career["name"] not in used_names:
                    if StreamDetector.validate_stream_alignment(career["name"], stream, self.data):
                        formatted = self.recommender.format_recommendation(career, stream, self.language)
                        validated_recommendations.append(formatted)
                        logger.info(f"Added rule-based recommendation to complete set: {career['name']}")
                        if len(validated_recommendations) >= 3:
                            break
            
            if len(validated_recommendations) < 3:
                logger.warning(f"Could only generate {len(validated_recommendations)} recommendations (target: 3)")
            
            return validated_recommendations[:3]
    
    def _build_profile_summary(self) -> str:
        """Build a summary of student profile for Gemini."""
        profile = self.profile.to_dict()
        summary_parts = []
        
        if profile.get("favourite_subjects"):
            summary_parts.append(f"Favourite Subjects: {profile['favourite_subjects']}")
        if profile.get("weak_subjects"):
            summary_parts.append(f"Weak Subjects: {profile['weak_subjects']}")
        if profile.get("marks_range"):
            summary_parts.append(f"Marks Range: {profile['marks_range']}")
        if profile.get("interests"):
            summary_parts.append(f"Interests: {profile['interests']}")
        if profile.get("stream"):
            summary_parts.append(f"Stream: {profile['stream']}")
        
        # Add stream-specific aptitude
        if profile.get("stream_aptitude"):
            summary_parts.append(f"Stream Aptitude: {json.dumps(profile['stream_aptitude'], ensure_ascii=False)}")
        
        return "\n".join(summary_parts)
    
    def _parse_gemini_recommendations(self, response_text: str, stream: str) -> List[Dict]:
        """Parse Gemini's JSON response into recommendation dictionaries."""
        try:
            # Clean response - remove markdown code blocks if present
            cleaned = response_text.strip()
            if cleaned.startswith("```json"):
                cleaned = cleaned[7:]
            elif cleaned.startswith("```"):
                cleaned = cleaned[3:]
            if cleaned.endswith("```"):
                cleaned = cleaned[:-3]
            cleaned = cleaned.strip()
            
            # Try to extract JSON array if there's extra text
            # Look for the first '[' and last ']'
            start_idx = cleaned.find('[')
            end_idx = cleaned.rfind(']')
            if start_idx != -1 and end_idx != -1 and end_idx > start_idx:
                cleaned = cleaned[start_idx:end_idx + 1]
            
            # Parse JSON
            recommendations = json.loads(cleaned)
            
            # Ensure it's a list
            if isinstance(recommendations, dict):
                recommendations = [recommendations]
            
            # Validate we have recommendations
            if not isinstance(recommendations, list):
                logger.error(f"Gemini response is not a list: {type(recommendations)}")
                raise ValueError("Gemini response is not a list")
            
            logger.info(f"Successfully parsed {len(recommendations)} recommendations from Gemini")
            
            # Log if we don't have exactly 3
            if len(recommendations) != 3:
                logger.warning(f"Gemini returned {len(recommendations)} recommendations instead of 3")
            
            return recommendations
        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse Gemini JSON response: {e}")
            logger.debug(f"Response text: {response_text[:500]}")
            raise
        except Exception as e:
            logger.error(f"Error parsing Gemini recommendations: {e}", exc_info=True)
            raise
    
    def _format_recommendations_response(self, recommendations: List[Dict]) -> str:
        """Format recommendations as final response with proper formatting."""
        if self.language == "mr":
            response = "‡§§‡•Å‡§Æ‡§ö‡•ç‡§Ø‡§æ ‡§™‡•ç‡§∞‡•ã‡§´‡§æ‡§á‡§≤‡§µ‡§∞ ‡§Ü‡§ß‡§æ‡§∞‡§ø‡§§, ‡§Ø‡•á‡§•‡•á 3 ‡§ï‡§∞‡§ø‡§Ö‡§∞ ‡§∂‡§ø‡§´‡§æ‡§∞‡§∏‡•Ä ‡§Ü‡§π‡•á‡§§:\n\n"
            for i, rec in enumerate(recommendations, 1):
                response += f"**{i}. {rec['name']}**\n\n"
                response += f"**‡§∏‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Æ ‡§î‡§ö‡§ø‡§§‡•ç‡§Ø:** {rec['stream_justification']}\n\n"
                response += f"**‡§∂‡•à‡§ï‡•ç‡§∑‡§£‡§ø‡§ï ‡§Æ‡§æ‡§∞‡•ç‡§ó:** {rec['pathway']}\n\n"
                response += f"**‡§™‡•ç‡§∞‡§µ‡•á‡§∂ ‡§™‡§∞‡•Ä‡§ï‡•ç‡§∑‡§æ:** {', '.join(rec['entrance_exams'])}\n\n"
                response += f"**‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï ‡§ï‡•å‡§∂‡§≤‡•ç‡§Ø‡•á:** {', '.join(rec['skills'])}\n\n"
                response += f"**‡§ú‡•ã‡§ñ‡•Ä‡§Æ/‡§Æ‡§∞‡•ç‡§Ø‡§æ‡§¶‡§æ:** {rec['risks']}\n\n"
                response += "---\n\n"
            
            response += "\n‚ö†Ô∏è **‡§Æ‡§π‡§§‡•ç‡§µ‡§æ‡§ö‡•á:** ‡§π‡•á ‡§Æ‡§æ‡§∞‡•ç‡§ó‡§¶‡§∞‡•ç‡§∂‡§® ‡§ï‡•á‡§µ‡§≥ ‡§∏‡•Ç‡§ö‡§ï ‡§Ü‡§π‡•á. ‡§ï‡•É‡§™‡§Ø‡§æ ‡§§‡•Å‡§Æ‡§ö‡§æ ‡§®‡§ø‡§∞‡•ç‡§£‡§Ø ‡§™‡•ç‡§∞‡§Æ‡§æ‡§£‡§ø‡§§ ‡§Æ‡§æ‡§®‡§µ‡•Ä ‡§ï‡§∞‡§ø‡§Ö‡§∞ ‡§ï‡§æ‡§â‡§®‡•ç‡§∏‡•á‡§≤‡§∞‡§∏‡•ã‡§¨‡§§ ‡§™‡•Å‡§∑‡•ç‡§ü‡•Ä ‡§ï‡§∞‡§æ."
        else:
            response = "**Based on your profile, here are 3 career recommendations:**\n\n"
            for i, rec in enumerate(recommendations, 1):
                response += f"**{i}. {rec['name']}**\n\n"
                response += f"**Stream Justification:** {rec['stream_justification']}\n\n"
                response += f"**Education Pathway:** {rec['pathway']}\n\n"
                response += f"**Entrance Exams:** {', '.join(rec['entrance_exams'])}\n\n"
                response += f"**Required Skills:** {', '.join(rec['skills'])}\n\n"
                response += f"**Risks/Limitations:** {rec['risks']}\n\n"
                response += "---\n\n"
            
            response += "\n‚ö†Ô∏è **Important:** This guidance is indicative only. Please confirm your decision with a certified human career counselor."
        
        return response
    
    def process_input(self, user_input: str) -> Tuple[str, bool]:
        """
        Process user input and return response.
        Returns: (response_text, is_complete)
        Enforces one-question-at-a-time rule.
        """
        if not user_input or not user_input.strip():
            if self.language == "mr":
                return "‡§ï‡•É‡§™‡§Ø‡§æ ‡§µ‡•à‡§ß ‡§â‡§§‡•ç‡§§‡§∞ ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡§æ.", False
            else:
                return "Please provide a valid answer.", False
        
        user_input = user_input.strip()
        
        # Phase: Welcome - handle before language detection
        if self.phase == self.PHASE_WELCOME:
            # Detect language on first input ONLY if not manually set
            if not self.language_manually_set:
                self._detect_language(user_input)
            
            # Move to next phase and return first question in current language
            self.phase = self.PHASE_GENERAL_QUESTIONS
            self.current_question_index = 0
            question = self._get_next_general_question()
            logger.debug(f"Welcome phase: language={self.language}, question={question.get('id', 'None') if question else 'None'}")
            if question:
                question_number = self.current_question_index + 1
                question_text = self._get_question_text(question, question_number, self.total_questions)
                if not question_text or question_text.strip() == "":
                    logger.error(f"Question text is empty for question {question.get('id', 'unknown')} in language {self.language}")
                    # Fallback to welcome message
                    return self._get_welcome_message(), False
                logger.info(f"Returning first question in language '{self.language}': {question_text[:50]}...")
                return question_text, False
            logger.warning("No question found, returning welcome message")
            return self._get_welcome_message(), False
        
        # Detect language on first input ONLY if not manually set (for other phases)
        if not self.language_manually_set and self.current_question_index == 0:
            self._detect_language(user_input)
        
        # Phase: General Questions
        if self.phase == self.PHASE_GENERAL_QUESTIONS:
            question = self._get_next_general_question()
            if question:
                logger.debug(f"Processing answer for question {question['id']}: {user_input[:50]}...")
                # Store answer
                self.profile.update(question["id"], user_input)
                self.current_question_index += 1
                logger.info(f"Stored answer for question {question['id']}, moving to question index {self.current_question_index}")
                
                # Check if more general questions
                next_question = self._get_next_general_question()
                if next_question:
                    logger.debug(f"Next general question available: {next_question['id']}")
                    question_number = self.current_question_index + 1
                    return self._get_question_text(next_question, question_number, self.total_questions), False
                else:
                    # All general questions answered, detect stream
                    logger.info("All general questions answered, detecting stream")
                    self.phase = self.PHASE_STREAM_CONFIRMATION
                    detected = self.stream_detector.detect_stream(
                        self.profile.get("favourite_subjects"),
                        self.profile.get("weak_subjects"),
                        self.profile.get("interests")
                    )
                    
                    if detected:
                        logger.info(f"Stream detected: {detected}")
                        self.detected_stream = detected
                        # Don't add question number to confirmation prompt
                        return self._generate_stream_confirmation_prompt(detected), False
                    else:
                        logger.warning("Stream detection returned None - asking user explicitly")
                        # Ambiguous, ask explicitly (this is not a numbered question)
                        name = self.profile.get("name", "").strip()
                        name_prefix = f"{name}, " if name else ""
                        if self.language == "mr":
                            return f"{name_prefix}‡§Æ‡§≤‡§æ ‡§•‡•ã‡§°‡•á ‡§Ö‡§ß‡§ø‡§ï ‡§Æ‡§æ‡§π‡§ø‡§§‡•Ä ‡§π‡§µ‡•Ä ‡§Ü‡§π‡•á. ‡§§‡•Å‡§Æ‡•ç‡§π‡•Ä ‡§∏‡§ß‡•ç‡§Ø‡§æ ‡§ï‡•ã‡§£‡§§‡•ç‡§Ø‡§æ ‡§∂‡•à‡§ï‡•ç‡§∑‡§£‡§ø‡§ï ‡§∏‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Æ‡§Æ‡§ß‡•ç‡§Ø‡•á ‡§Ü‡§π‡§æ‡§§? (PCM/PCB/Commerce/Arts/Vocational)", False
                        else:
                            return f"{name_prefix}I'd like to understand better. Which academic stream are you currently in? (PCM/PCB/Commerce/Arts/Vocational)", False
        
        # Phase: Stream Confirmation
        if self.phase == self.PHASE_STREAM_CONFIRMATION:
            user_input_lower = user_input.lower()
            
            # Check for yes/no or direct stream input
            stream = None
            
            if self.language == "mr":
                if "‡§π‡•ã‡§Ø" in user_input_lower or "yes" in user_input_lower or "‡§π‡•ã" in user_input_lower:
                    if hasattr(self, 'detected_stream'):
                        stream = self.detected_stream
                        self.profile.set_stream(stream)
                    else:
                        # Should not happen, but handle gracefully
                        name = self.profile.get("name", "").strip()
                        name_prefix = f"{name}, " if name else ""
                        return f"{name_prefix}‡§ï‡•É‡§™‡§Ø‡§æ ‡§§‡•Å‡§Æ‡§ö‡§æ ‡§∏‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Æ ‡§∏‡•ç‡§™‡§∑‡•ç‡§ü ‡§ï‡§∞‡§æ (PCM/PCB/Commerce/Arts/Vocational)", False
                elif "‡§®‡§æ‡§π‡•Ä" in user_input_lower or "no" in user_input_lower or "‡§®" in user_input_lower:
                    name = self.profile.get("name", "").strip()
                    name_prefix = f"{name}, " if name else ""
                    return f"{name_prefix}‡§ï‡•É‡§™‡§Ø‡§æ ‡§§‡•Å‡§Æ‡§ö‡§æ ‡§∏‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Æ ‡§∏‡•ç‡§™‡§∑‡•ç‡§ü ‡§ï‡§∞‡§æ (PCM/PCB/Commerce/Arts/Vocational)", False
                else:
                    # Direct stream input
                    stream_map = {
                        "pcm": "PCM", "pcb": "PCB", "commerce": "Commerce",
                        "arts": "Arts", "vocational": "Vocational"
                    }
                    stream = stream_map.get(user_input_lower, None)
                    if stream:
                        self.profile.set_stream(stream)
                    else:
                        name = self.profile.get("name", "").strip()
                        name_prefix = f"{name}, " if name else ""
                        return f"{name_prefix}‡§Ö‡§µ‡•à‡§ß ‡§∏‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Æ. ‡§ï‡•É‡§™‡§Ø‡§æ PCM, PCB, Commerce, Arts ‡§ï‡§ø‡§Ç‡§µ‡§æ Vocational ‡§®‡§ø‡§µ‡§°‡§æ.", False
            else:
                # English
                if "yes" in user_input_lower or "y" == user_input_lower:
                    if hasattr(self, 'detected_stream'):
                        stream = self.detected_stream
                        self.profile.set_stream(stream)
                    else:
                        name = self.profile.get("name", "").strip()
                        name_prefix = f"{name}, " if name else ""
                        return f"{name_prefix}Please specify your stream (PCM/PCB/Commerce/Arts/Vocational)", False
                elif "no" in user_input_lower or "n" == user_input_lower:
                    name = self.profile.get("name", "").strip()
                    name_prefix = f"{name}, " if name else ""
                    return f"{name_prefix}Please specify your stream (PCM/PCB/Commerce/Arts/Vocational)", False
                else:
                    stream_map = {
                        "pcm": "PCM", "pcb": "PCB", "commerce": "Commerce",
                        "arts": "Arts", "vocational": "Vocational"
                    }
                    stream = stream_map.get(user_input_lower, None)
                    if stream:
                        self.profile.set_stream(stream)
                    else:
                        name = self.profile.get("name", "").strip()
                        name_prefix = f"{name}, " if name else ""
                        return f"{name_prefix}Invalid stream. Please choose PCM, PCB, Commerce, Arts, or Vocational.", False
            
            # Stream confirmed, move to stream-specific questions
            if self.profile.get("stream"):
                confirmed_stream = self.profile.get("stream")
                logger.info(f"Stream confirmed: {confirmed_stream}, moving to stream-specific questions")
                self.phase = self.PHASE_STREAM_QUESTIONS
                self.stream_questions = self._get_stream_questions(confirmed_stream)
                self.stream_question_index = 0
                self.current_question_index = 0  # Reset for stream questions
                logger.debug(f"Loaded {len(self.stream_questions)} stream-specific questions for {confirmed_stream}")
                
                if self.stream_questions:
                    question = self.stream_questions[self.stream_question_index]
                    logger.debug(f"First stream question: {question['id']}")
                    # Calculate question number: general_count (already asked) + stream_question_index + 1
                    general_count = len(self.data["questions"]["general"])
                    question_number = general_count + self.stream_question_index + 1
                    logger.debug(f"Question number calculation: {general_count} (general) + {self.stream_question_index + 1} (stream) = {question_number}")
                    return self._get_question_text(question, question_number, self.total_questions), False
                else:
                    # No stream-specific questions, move to recommendations
                    logger.info(f"No stream-specific questions for {confirmed_stream}, generating recommendations")
                    self.phase = self.PHASE_RECOMMENDATIONS
                    recommendations = self._generate_recommendations()
                    logger.info(f"Generated {len(recommendations)} recommendations")
                    response = self._format_recommendations_response(recommendations)
                    self.phase = self.PHASE_COMPLETE
                    return response, True
        
        # Phase: Stream-specific Questions
        if self.phase == self.PHASE_STREAM_QUESTIONS:
            if hasattr(self, 'stream_questions') and self.stream_question_index < len(self.stream_questions):
                question = self.stream_questions[self.stream_question_index]
                logger.debug(f"Processing stream question {question['id']}: {user_input[:50]}...")
                # Store answer in stream_aptitude
                if "stream_aptitude" not in self.profile.data:
                    self.profile.data["stream_aptitude"] = {}
                self.profile.data["stream_aptitude"][question["id"]] = user_input
                
                self.stream_question_index += 1
                logger.info(f"Stored stream answer for {question['id']}, question {self.stream_question_index}/{len(self.stream_questions)}")
                
                # Check if more stream questions
                if self.stream_question_index < len(self.stream_questions):
                    next_question = self.stream_questions[self.stream_question_index]
                    logger.debug(f"Next stream question: {next_question['id']}")
                    # Calculate question number: general_count (already asked) + stream_question_index + 1
                    general_count = len(self.data["questions"]["general"])
                    question_number = general_count + self.stream_question_index + 1
                    logger.debug(f"Question number calculation: {general_count} (general) + {self.stream_question_index + 1} (stream) = {question_number}")
                    return self._get_question_text(next_question, question_number, self.total_questions), False
                else:
                    # All questions answered, generate recommendations
                    logger.info("All stream-specific questions answered, generating recommendations")
                    self.phase = self.PHASE_RECOMMENDATIONS
                    recommendations = self._generate_recommendations()
                    logger.info(f"Generated {len(recommendations)} recommendations")
                    response = self._format_recommendations_response(recommendations)
                    self.phase = self.PHASE_COMPLETE
                    return response, True
        
        # Phase: Complete
        if self.phase == self.PHASE_COMPLETE:
            if self.language == "mr":
                return "‡§∏‡§Ç‡§≠‡§æ‡§∑‡§£ ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§ù‡§æ‡§≤‡•á ‡§Ü‡§π‡•á. ‡§™‡•Å‡§®‡•ç‡§π‡§æ ‡§∏‡•Å‡§∞‡•Ç ‡§ï‡§∞‡§£‡•ç‡§Ø‡§æ‡§∏‡§æ‡§†‡•Ä, ‡§ï‡•É‡§™‡§Ø‡§æ 'Restart' ‡§¨‡§ü‡§£ ‡§µ‡§æ‡§™‡§∞‡§æ.", True
            else:
                return "Conversation is complete. To start again, please use the 'Restart' button.", True
        
        # Fallback
        if self.language == "mr":
            return "‡§Ö‡§®‡§™‡•á‡§ï‡•ç‡§∑‡§ø‡§§ ‡§§‡•ç‡§∞‡•Å‡§ü‡•Ä. ‡§ï‡•É‡§™‡§Ø‡§æ ‡§™‡•Å‡§®‡•ç‡§π‡§æ ‡§™‡•ç‡§∞‡§Ø‡§§‡•ç‡§® ‡§ï‡§∞‡§æ.", False
        else:
            return "Unexpected error. Please try again.", False
    
    def reset(self):
        """Reset agent state completely."""
        current_language = self.language  # Preserve language
        language_was_set = self.language_manually_set  # Preserve manual set flag
        self.profile.reset()
        self.llm.clear_history()
        self.phase = self.PHASE_WELCOME
        self.current_question_index = 0
        self.stream_question_index = 0
        self.language = current_language  # Restore language
        self.language_manually_set = language_was_set  # Restore flag
        if hasattr(self, 'detected_stream'):
            delattr(self, 'detected_stream')
        if hasattr(self, 'stream_questions'):
            delattr(self, 'stream_questions')
        logger.info(f"Agent reset complete (language preserved: {self.language})")
    
    def get_current_phase(self) -> str:
        """Get current conversation phase."""
        return self.phase